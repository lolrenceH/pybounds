{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f1902de9ebff5a59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:18.990777Z",
     "start_time": "2024-12-17T10:35:18.973608Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pybounds import Simulator, SlidingEmpiricalObservabilityMatrix, FisherObservability, SlidingFisherObservability, ObservabilityMatrixImage, colorline\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "def log_shapes(pytree):\n",
    "    def log_leaf(path, leaf=()):\n",
    "        if isinstance(leaf, jnp.ndarray) or isinstance(leaf, np.ndarray):\n",
    "            print(f\"Path: {path}, Shape: {leaf.shape}\")\n",
    "    jax.tree_util.tree_map_with_path(log_leaf, pytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34921fe584d11b1",
   "metadata": {},
   "source": [
    "# Define system dynamics and measurements\n",
    "This example uses a model of an insect flying in the presence of wind.\n",
    "\n",
    "See the following reference for details:\n",
    "\n",
    "Floris van Breugel\n",
    "A Nonlinear Observability Analysis of Ambient Wind Estimation with Uncalibrated Sensors, Inspired by Insect Neural Encoding\n",
    "2021 60th IEEE Conference on Decision and Control (CDC)\n",
    "DOI: 10.1109/CDC45484.2021.9683219\n",
    "\n",
    "The system dynamics are described by seven primary states:\n",
    "* altitude $z$\n",
    "* parallel velocity $v_{\\parallel}$\n",
    "* perpendicular velocity $v_{\\perp}$\n",
    "* heading $\\phi$\n",
    "* angular velocity $\\dot{\\phi}$\n",
    "* wind speed $w$\n",
    "* wind direction $\\zeta$\n",
    "\n",
    "And the system dynamics are given by\n",
    "$$\n",
    "\\dot{\\mathbf{x}} = \\begin{bmatrix} \\dot{z} \\\\ \\dot{v}_{\\parallel} \\\\ \\dot{v}_{\\perp} \\\\ \\dot{\\phi} \\\\ \\ddot{\\phi} \\\\ \\dot{w}  \\\\ \\dot{\\zeta} \\end{bmatrix} = \n",
    "f(\\mathbf{x}) = \\begin{bmatrix} \n",
    "\\dot{z} \\\\\n",
    "\\frac{1}{m}(k_{m_1}u_{\\parallel} - C_{\\parallel} a_{\\parallel}) + v_{\\perp} \\dot{\\phi} \\\\\n",
    " \\frac{1}{m}(k_{m_3}u_{\\perp} - C_{\\perp} a_{\\perp}) - v_{\\parallel} \\dot{\\phi} \\\\\n",
    "  \\dot{\\phi} \\\\\n",
    "   \\frac{1}{I}(k_{m_4}u_{\\phi} - C_{\\phi} \\dot{\\phi} + k_{m_2} u_{\\perp}) \\\\\n",
    "    \\dot{w} \\\\\n",
    "     \\dot{\\zeta} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where the air velocity is given by\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} a_{\\parallel} \\\\ a_{\\perp} \\end{bmatrix} =  \\begin{bmatrix} v_{\\parallel} - w \\cos(\\phi - \\zeta) \\\\ v_{\\perp} + w \\sin(\\phi - \\zeta) \\end{bmatrix}\n",
    "$$\n",
    "The inputs $u_{\\bullet}$ are\n",
    "* parallel thrust force $u_{\\parallel}$\n",
    "* perpendicular thrust force $u_{\\perp}$\n",
    "* turning torque $u_{\\phi}$\n",
    "\n",
    "The inertia parameters (mass $m$ and inertia $I$), damping terms $C_{\\bullet}$, and motor calibration coefficients $k_{m_{\\bullet}}$ can also be considered states. Other auxiliary states, like the $x$ and $y$ position can also be added.\n",
    "\n",
    "The putative system measurements are:\n",
    "* heading $\\phi$\n",
    "* ground speed angle $\\psi$\n",
    "* apparent airflow angle $\\gamma$\n",
    "* apparent airflow magnitude $a$\n",
    "* ground speed magnitude $g$\n",
    "* optic flow $g/z$\n",
    "\n",
    "Where the measurement function is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = h(\\mathbf{x}) = \\begin{bmatrix} \\phi \\\\ \\psi \\\\ \\gamma  \\\\ a \\\\ g \\\\ r \\end{bmatrix} = \n",
    "\\begin{bmatrix} \\phi \\\\\n",
    "\\arctan(v_{\\perp}/ v_{\\parallel}) \\\\\n",
    "\\arctan(a_{\\perp} / a_{\\parallel}) \\\\\n",
    "\\sqrt{a_{\\parallel}^2 + a_{\\perp}^2} \\\\\n",
    "\\sqrt{v_{\\parallel}^2 + v_{\\perp}^2} \\\\\n",
    "\\sqrt{v_{\\parallel}^2 + v_{\\perp}^2} / z \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b6974d8c985a97",
   "metadata": {},
   "source": [
    "## Define dynamics function\n",
    "The dynamics function takes in a list of states $X$ and a list of inputs $U$ and outputs the derivative of the states.\n",
    "\n",
    "The optional state & input names must be in the same order as the states & inputs in $X$ & $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "afa5cf8d9cf2a145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:19.054565Z",
     "start_time": "2024-12-17T10:35:19.038557Z"
    }
   },
   "outputs": [],
   "source": [
    "state_names = [\n",
    "                'x',  # x position [m]\n",
    "                'y',  # y position [m]\n",
    "                'v_para',  # parallel ground velocity [m/s]\n",
    "                'v_perp',  # perpendicular ground velocity [m/s]\n",
    "                'phi', # heading [rad]\n",
    "                'w',  # ambient wind speed [m/s]\n",
    "                'zeta',  # ambient wind angle [rad]\n",
    "                ]\n",
    "\n",
    "input_names = [\n",
    "                'u_para',  # translational speed [m/s]\n",
    "                'u_phi',  # angular velocity [rad/s]\n",
    "                'u_para_dot',  # translational acceleration [m/s^2] \n",
    "                'u_zeta_dot',\n",
    "                'u_w_dot'  \n",
    "                ]\n",
    "\n",
    "def f(X, U):\n",
    "    '''\n",
    "    Return Xdot given X and U\n",
    "    \n",
    "    X: state vector\n",
    "        v_para: ground velocity in the direction parallel to head direction (egocentric frame) [m/s]\n",
    "        v_perp: ground velocity perpendicular to head direction (egocentric frame) [m/s]\n",
    "        phi: heading [rad]\n",
    "        w: wind speed [m/s]\n",
    "        zeta: wind angle [rad]\n",
    "    U: input vector assuming actions have been squashed and scaled\n",
    "        u_para: translational speed [m/s]\n",
    "        u_phi: angular velocity [rad/s]\n",
    "        u_para_dot: translational acceleration [m/s^2]\n",
    "    '''\n",
    "    # States\n",
    "    # v_para, v_perp, phi, w, zeta = X\n",
    "    x, y, v_para, v_perp, phi, w, zeta = X\n",
    "    \n",
    "    # Inputs\n",
    "    u_para, u_phi, u_para_dot, u_zeta_dot, u_w_dot = U # keep u_para because it is in the observation matrix\n",
    "\n",
    "    # Dynamics\n",
    "    w_dot = 0*w # wind speed is constant\n",
    "    # w_dot = u_w_dot # wind speed is constant\n",
    "    zeta_dot = u_zeta_dot # for discontinuous wind direction change\n",
    "    phi_dot = u_phi # angular velocity is controlled by agent\n",
    "    # v_perp_dot = - w * np.cos(phi - zeta) * u_phi # omit terms that would be zero\n",
    "    v_perp_dot = -w * np.cos(phi - zeta) * u_phi + w * np.cos(phi - zeta) * zeta_dot - w_dot * np.sin(phi - zeta) \n",
    "    # v_para_dot = - w * np.sin(phi - zeta) * u_phi + u_para_dot # omit terms that would be zero\n",
    "    v_para_dot = -w * np.sin(phi - zeta) * u_phi + w * np.sin(phi - zeta) * zeta_dot + w_dot * np.cos(phi - zeta) + u_para_dot\n",
    "    x_dot = v_para * np.cos(phi) - v_perp * np.sin(phi)\n",
    "    y_dot = v_para * np.sin(phi) + v_perp * np.cos(phi)\n",
    "\n",
    "    # Package and return xdot\n",
    "    X_dot = [x_dot, y_dot, v_para_dot, v_perp_dot, phi_dot, w_dot, zeta_dot]\n",
    "    # X_dot = [v_para_dot, v_perp_dot, phi_dot, w_dot, zeta_dot]\n",
    "\n",
    "    return X_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67631fba42a02c",
   "metadata": {},
   "source": [
    "## Define measurement function\n",
    "The measurement function takes in a list of states $X$ and a list of inputs $U$ and outputs the measurements $Y$.\n",
    "\n",
    "The optional measurement names must be in the same order as the measurements in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fd93d3dbf5535e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:19.069797Z",
     "start_time": "2024-12-17T10:35:19.055558Z"
    }
   },
   "outputs": [],
   "source": [
    "measurement_names = ['phi', 'appWind', 'psi'] # heading, apparent wind parallel component, drift angle/egocentric course angle\n",
    "def h(X, U):\n",
    "    '''\n",
    "    Measurement functions - input is the state and control input; output is the measurement\n",
    "    Assuming control signals are squashed and scaled\n",
    "    '''\n",
    "    # States\n",
    "    x, y, v_para, v_perp, phi, w, zeta = X\n",
    "    # v_para, v_perp, phi, w, zeta = X\n",
    "    \n",
    "    # Inputs\n",
    "    u_para, u_phi, u_para_dot, u_zeta_dot, u_w_dot = U\n",
    "    \n",
    "    # Measurements\n",
    "    # Heading\n",
    "    phi = phi # heading is directly observable \n",
    "    # Apparent wind\n",
    "    appWind = - u_para # equal and opposite to translational speed which is in line with head direction and thus have only a parallel component\n",
    "    # Course direction in fly reference frame\n",
    "    psi = np.arctan2(v_perp, v_para) # drift angle / egocentric course angle  # TODO numerically check if this is actually the drift angle - yes according to Ben\n",
    "    \n",
    "    # # Unwrap angles - Elliot unwrap the angles s.t. they are continuous - no more snapping back to 0\n",
    "    if np.array(phi).ndim > 0:\n",
    "        if np.array(phi).shape[0] > 1:\n",
    "            phi = np.unwrap(phi)\n",
    "            psi = np.unwrap(psi)\n",
    "    #         # gamma = np.unwrap(gamma)\n",
    "\n",
    "    # Measurements\n",
    "    Y  = [phi, appWind, psi]\n",
    "\n",
    "    # Return measurement\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce822781609ebf9",
   "metadata": {},
   "source": [
    "## Set time-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "af1c2296132affea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:19.085302Z",
     "start_time": "2024-12-17T10:35:19.070797Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = 0.04  # [s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba91f3406a7ff3",
   "metadata": {},
   "source": [
    "# Create simulator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a2ba514ec911b5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:19.132932Z",
     "start_time": "2024-12-17T10:35:19.086303Z"
    }
   },
   "outputs": [],
   "source": [
    "simulator = Simulator(f, h, dt=dt, state_names=state_names, input_names=input_names, measurement_names=measurement_names)\n",
    "\n",
    "# Can also set the number of state (n) & inputs (m0 instead of state & input names)\n",
    "# simulator = Simulator(f, h, dt=dt, n=len(state_names), m=len(input_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392f54a07498b2f",
   "metadata": {},
   "source": [
    "# Load inference-time trajectories to pull out control signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7d225c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fname = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_14421_37e2cd4be4c96943d0341849b40f81eb/noisy3x5b5.pkl'\n",
    "# load pkl file\n",
    "import pickle\n",
    "import numpy as np\n",
    "with open(log_fname, 'rb') as f_handle:\n",
    "    episode_logs = pickle.load(f_handle)\n",
    "print('Loaded episode logs from', log_fname)\n",
    "print('Number of episodes:', len(episode_logs))\n",
    "print('Episodes contain:', episode_logs[0].keys())\n",
    "print('For more info on pkl content see /src/JH_boilerplate/dev_test/env/explore_pkl.ipynb')\n",
    "# episode_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cc40c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_actions = episode_logs[1]['actions']\n",
    "# TODO: function that squashes and scales actions. output is u_sim a dict with keys 'u_para', 'u_phi', 'u_para_dot', and values are np arrays\n",
    "# stack a list of actions into a 2D array\n",
    "raw_actions = np.stack(raw_actions)\n",
    "\n",
    "def squash_and_scale_actions(raw_actions, dt):\n",
    "    '''\n",
    "    See /src/JH_boilerplate/dev_test/env/explore_pkl.ipynb\n",
    "    \n",
    "    Logged actions are the raw outputs of the agent. They need to be translated into the control inputs for the simulator.\n",
    "    1. Squash the actions to [0, 1]\n",
    "    2. Scale the actions to the fly's capabilities\n",
    "    3. Calculate the translational acceleration - new need to be checked\n",
    "    4. Return a dictionary of control inputs for the simulator\n",
    "    \n",
    "    Note at agent_angle_rad_t0, this is obtained by the following steps:\n",
    "      - t = -1: env generates an obs by env.reset()\n",
    "      - t = 0: policy creates an action based on the obs\n",
    "      - t = 0: env.step(action)\n",
    "          - t = 0: obs_t0 = obs_t(-1) + action_t0  (obs_t-1 based on how the angle was initialized which is NOT documented in the eps logs)\n",
    "      - t = 1: env generates an obs\n",
    "    '''\n",
    "    \n",
    "    def squash_action(x):\n",
    "      return np.clip((np.tanh(x) + 1)/2, 0.0, 1.0) # squash action, center and scale to [0, 1], per action treatment \n",
    "\n",
    "    if type(raw_actions) is list:\n",
    "      raw_actions = np.stack(raw_actions)\n",
    "      \n",
    "    # Vectorize the function # TODO sanity check\n",
    "    vsquash_action = np.vectorize(squash_action)\n",
    "\n",
    "    # Apply the vectorized function to the array\n",
    "    actions = vsquash_action(raw_actions)\n",
    "\n",
    "    # Scale actions by fly capabilities \n",
    "    actions[:, 0] = actions[:, 0] * 2.0 # Max agent speed in m/s\n",
    "    actions[:, 1] = (actions[:, 1] - 0.5) * 6.25*np.pi # Max agent CW/CCW turn per second\n",
    "\n",
    "    # Calculate translational acceleration\n",
    "    acc = np.diff(actions[:, 0]) / dt # checked - this is correct\n",
    "    # acc = np.insert(acc, 0, 0) # first acceleration is 0\n",
    "    \n",
    "    # Omit the first action. See function description.\n",
    "    u_sim = {'u_para': actions[1:, 0], 'u_phi': actions[1:, 1], 'u_para_dot': acc} \n",
    "    print('u_sim shapes', u_sim['u_para'].shape, u_sim['u_phi'].shape, u_sim['u_para_dot'].shape)\n",
    "    \n",
    "    return u_sim\n",
    "\n",
    "u_sim = squash_and_scale_actions(raw_actions, dt) # can be pulled from traj_df_stacked['step'] and 'turn'; just need to scale but already squashed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddd599",
   "metadata": {},
   "source": [
    "# Pull out ground truth states and measurements to be simulated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "859d0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tamagotchi.eval.log_analysis as log_analysis\n",
    "number_of_eps = 240 # pull all episodes\n",
    "dataset = 'noisy3x5b5'\n",
    "# dataset = 'constantx5b5'\n",
    "exp_folder = 'eval'\n",
    "model_fname = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/weights/plume_14421_37e2cd4be4c96943d0341849b40f81eb.pt'\n",
    "# traj_df_stacked = log_analysis.get_eval_dfs_and_stack_them(model_fname, dataset, number_of_eps, exp_dir=exp_folder, # full_model_dir = args.model_dir, \n",
    "#                                                            oob_only=False,\n",
    "#                                                            balanced=False,\n",
    "#                                                            verbose=True) # this uses get_traj_tmp\n",
    "\n",
    "# based on open_loop_perturbation.py\n",
    "eval_folder = model_fname.replace('weights', exp_folder).replace('.pt', '/')\n",
    "selected_df = log_analysis.get_selected_df(eval_folder, [dataset],\n",
    "                                        n_episodes_home=240,\n",
    "                                        n_episodes_other=240,  \n",
    "                                        balanced=False,\n",
    "                                        oob_only=False,\n",
    "                                        verbose=True)\n",
    "\n",
    "# traj_df_stacked2, stacked_neural_activity = log_analysis.get_traj_and_activity_and_stack_them(selected_df, \n",
    "traj_df_stacked, stacked_neural_activity = log_analysis.get_traj_and_activity_and_stack_them(selected_df, \n",
    "                                                                                            obtain_neural_activity = True, \n",
    "                                                                                            obtain_traj_df = True, \n",
    "                                                                                            get_traj_tmp = True,\n",
    "                                                                                            extended_metadata = True) # get_traj_tmp \n",
    "\n",
    "# twp methods of getting traj are not equivalent - get_eval_dfs_and_stack_them has loc_x/y_dot\n",
    "    # get_traj_and_activity_and_stack_them has tidx\n",
    "    # the columns used for simulator are identical\n",
    "# cols1 = traj_df_stacked.columns\n",
    "# cols2 = traj_df_stacked_2.columns\n",
    "# unique_cols1 = [col for col in cols1 if col not in cols2]\n",
    "# unique_cols2 = [col for col in cols2 if col not in cols1]\n",
    "# print('unique_cols1', unique_cols1)\n",
    "# print('unique_cols2', unique_cols2)\n",
    "\n",
    "epoch_traj_df = traj_df_stacked[traj_df_stacked['ep_idx'] == 1]\n",
    "epoch_latent_activity = stacked_neural_activity[epoch_traj_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "791f0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict = {'x':[], 'y':[], 'v_para': [], 'v_perp': [], 'phi': [], 'w': [], 'zeta': [], \n",
    "           'psi_ego_course_dir': [], 'v_allo': []}\n",
    "\n",
    "# gt_dict = {'v_para': [], 'v_perp': [], 'phi': [], 'w': [], 'zeta': [], 'psi_ego_course_dir': [], 'v_allo': []}\n",
    "\n",
    "gt_dict['x'] = epoch_traj_df['loc_x'].values\n",
    "gt_dict['y'] = epoch_traj_df['loc_y'].values\n",
    "gt_dict['phi'] = np.angle(epoch_traj_df['agent_angle_x'] + 1j*epoch_traj_df['agent_angle_y'], deg=False)\n",
    "gt_dict['w'] = np.round(epoch_traj_df['wind_speed_ground'].values, 3)\n",
    "gt_dict['zeta'] = epoch_traj_df['wind_angle_ground_theta'].values # normalized by pi and then shifted to 0-1\n",
    "gt_dict['psi_ego_course_dir'] = epoch_traj_df['ego_course_direction_theta'].values # normalized by pi and then shifted to 0-1\n",
    "gt_dict['v_allo'] = np.stack(epoch_traj_df['allo_ground_velocity'].values) # PEv3: (np.array(self.agent_location) - self.agent_location_last)/self.dt; calc'd in get_eval_dfs_and_stack_them\n",
    "gt_dict['v_allo_dt'] = np.diff(gt_dict['v_allo']) / dt # acceleration\n",
    "# scale angles from 0-1 to -pi to pi\n",
    "gt_dict['zeta'] = np.pi * (2*gt_dict['zeta'] - 1)\n",
    "gt_dict['psi_ego_course_dir'] = np.pi * (2*gt_dict['psi_ego_course_dir'] - 1)\n",
    "\n",
    "gt_dict['v_para'] = np.cos(gt_dict['psi_ego_course_dir']) * np.linalg.norm(np.stack(gt_dict['v_allo']), axis=1) # cos(psi) * g = v_para\n",
    "gt_dict['v_perp'] = np.sin(gt_dict['psi_ego_course_dir']) * np.linalg.norm(np.stack(gt_dict['v_allo']), axis=1) # sin(psi) * g = v_perp\n",
    "\n",
    "u_sim['u_zeta_dot'] = np.diff(gt_dict['zeta']) / dt\n",
    "u_sim['u_w_dot'] = np.diff(gt_dict['w']) / dt\n",
    "log_shapes(gt_dict) # expected to have one more time point at the end\n",
    "log_shapes(u_sim) # 0th control signal is omitted\n",
    "# log_shapes(gt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b3978",
   "metadata": {},
   "source": [
    "# Compare control signals with ground truth - acc and step check out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b455a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_para_dot is calculated correctly in that it matches the airspeed acceleration of the agent\n",
    "    # the airspeed acceleration of the agent checked out in that it pointed in the head direction\n",
    "air_velocity = np.stack(epoch_traj_df['air_velocity'].values)\n",
    "air_velocity_angle = np.angle(air_velocity[:, 0] + 1j*air_velocity[:, 1], deg=False)\n",
    "air_velocity_mag = np.linalg.norm(air_velocity, axis=1)\n",
    "air_velocity_acc = np.diff(air_velocity_mag) / dt\n",
    "print(np.allclose(air_velocity_acc, u_sim['u_para_dot'], atol=1e-4))\n",
    "\n",
    "agent_angle = np.angle(epoch_traj_df['agent_angle_x'].values + 1j*epoch_traj_df['agent_angle_y'].values, deg=False)\n",
    "print(np.allclose(air_velocity_angle, agent_angle, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45b1d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get acceleration in airspeed from ground truth\n",
    "epoch_traj_df['step_scaled'] = epoch_traj_df['step'] * 2\n",
    "epoch_traj_df['u_para_dot'] = epoch_traj_df['step_scaled'].diff() / dt\n",
    "\n",
    "# are epoch_traj_df['u_para_dot'] and u_sim['u_para_dot'] the same, allow for a small tolerance? YES\n",
    "print(np.allclose(epoch_traj_df['u_para_dot'].values[1:], u_sim['u_para_dot'], atol=1e-4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d4ce232258a9d",
   "metadata": {},
   "source": [
    "# Simulate with control inputs to see if it matches ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "95ee0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = np.array([gt_dict['x'][0], gt_dict['y'][0], gt_dict['v_para'][0], gt_dict['v_perp'][0], gt_dict['phi'][0], gt_dict['w'][0], gt_dict['zeta'][0]])\n",
    "x0 = {'x': gt_dict['x'][0], 'y': gt_dict['y'][0], 'v_para': gt_dict['v_para'][0], 'v_perp': gt_dict['v_perp'][0], 'phi': gt_dict['phi'][0], 'w': gt_dict['w'][0], 'zeta': gt_dict['zeta'][0]}\n",
    "# x0 = np.array([gt_dict['v_para'][0], gt_dict['v_perp'][0], gt_dict['phi'][0], gt_dict['w'][0], gt_dict['zeta'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "32a99e267401caad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:21.531213Z",
     "start_time": "2024-12-17T10:35:21.501211Z"
    }
   },
   "outputs": [],
   "source": [
    "t_sim, x_sim, u_sim, y_sim = simulator.simulate(x0=x0, mpc=False, u=u_sim, return_full_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4a9ed9ddffb73216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:22.497984Z",
     "start_time": "2024-12-17T10:35:21.532202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot state\n",
    "# simulator.plot('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9e261",
   "metadata": {},
   "source": [
    "# Plot the ground truth and the simulated trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "56878fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ground truth\n",
    "# plot each state in a separate plot, where x_sim is a dict \n",
    "gt_dict['phi'] = np.unwrap(gt_dict['phi'])\n",
    "fig, axs = plt.subplots(7, 1, figsize=(10, 15)) # x y loc\n",
    "# fig, axs = plt.subplots(5, 1, figsize=(10, 15))\n",
    "for i, state_name in enumerate(state_names):\n",
    "    axs[i].plot(t_sim, x_sim[state_name], label='sim')\n",
    "    axs[i].plot(t_sim, gt_dict[state_name][:-1], label='gt')\n",
    "    axs[i].set_title(state_name)\n",
    "    axs[i].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1813a852673708f",
   "metadata": {},
   "source": [
    "# Observability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e7ecd6c29e122",
   "metadata": {},
   "source": [
    "## Construct observability matrix in sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1816060219c9f891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:22.513429Z",
     "start_time": "2024-12-17T10:35:22.498972Z"
    }
   },
   "outputs": [],
   "source": [
    "w = 10  # window size, set to None to use entire time-series as one window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6d3208ab8cebb1f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.079497Z",
     "start_time": "2024-12-17T10:35:22.515430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct O in sliding windows\n",
    "st = time.time()\n",
    "SEOM = SlidingEmpiricalObservabilityMatrix(simulator, t_sim, x_sim, u_sim, w=w, eps=1e-6)\n",
    "et = time.time()\n",
    "print('elapsed time:', et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2ea89c4c3fdd5747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.094929Z",
     "start_time": "2024-12-17T10:35:25.079497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get O's\n",
    "O_sliding = SEOM.get_observability_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "55b15a9e5ad692e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.110935Z",
     "start_time": "2024-12-17T10:35:25.095931Z"
    }
   },
   "outputs": [],
   "source": [
    "n_window = len(O_sliding)\n",
    "print(n_window, 'windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1cedf79182d82be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.437683Z",
     "start_time": "2024-12-17T10:35:25.111938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize first sliding observability matrix, this will throw errors if O is too big\n",
    "OI = ObservabilityMatrixImage(O_sliding[0], cmap='bwr')\n",
    "OI.plot(scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0469dc7863680",
   "metadata": {},
   "source": [
    "## Compute Fisher information matrix & inverse for first window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "451fd6cf6383e439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.453689Z",
     "start_time": "2024-12-17T10:35:25.438686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set each sensor noise level\n",
    "sensor_noise = {'phi': 0.0001, 'appWind': 0.0001, 'psi': 0.0001}\n",
    "# sensor_noise = {'phi': 0.1, 'appWind': 0.1, 'psi': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0510dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEOM.O_df_sliding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9aaaf5056bf75fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.469693Z",
     "start_time": "2024-12-17T10:35:25.454690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the Fisher information & Chernoff inverse\n",
    "FO = FisherObservability(SEOM.O_df_sliding[0], R=None, sensor_noise_dict=sensor_noise, lam=1e-12)\n",
    "\n",
    "# Can also set R directly as matrix or as scalar\n",
    "# FO = FisherObservability(SEOM.O_df_sliding[0], R=0.1*np.eye(O_sliding[0].shape[0]), lam=1e-6)\n",
    "# FO = FisherObservability(SEOM.O_df_sliding[0], R=0.1, lam=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7473d533d4f1910c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.484720Z",
     "start_time": "2024-12-17T10:35:25.470694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the Fisher information, inverse, and R matrix\n",
    "F, F_inv, R = FO.get_fisher_information()\n",
    "F_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ace27d3f55c0f",
   "metadata": {},
   "source": [
    "## Compute Fisher information matrix & inverse for each sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "94b30b60ed5543e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.499573Z",
     "start_time": "2024-12-17T10:35:25.484720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose sensors to use from O\n",
    "o_sensors = ['phi', 'appWind', 'psi']\n",
    "\n",
    "# Chose states to use from O\n",
    "o_states = [\n",
    "                # 'x',  # x position [m]\n",
    "                # 'y',  # y position [m]\n",
    "                'v_para',  # parallel ground velocity [m/s]\n",
    "                'v_perp',  # perpendicular ground velocity [m/s]\n",
    "                # 'phi', # heading [rad]\n",
    "                'w',  # ambient wind speed [m/s]\n",
    "                'zeta',  # ambient wind angle [rad]\n",
    "                ]\n",
    "\n",
    "# Choose time-steps to use from O\n",
    "window_size = 10\n",
    "o_time_steps = np.arange(0, window_size, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b77d1363934e9933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.687098Z",
     "start_time": "2024-12-17T10:35:25.500574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the Fisher information & inverse for each window and store the minimum error variance\n",
    "SFO = SlidingFisherObservability(SEOM.O_df_sliding, time=SEOM.t_sim, lam=1e-6, R=None, sensor_noise_dict=sensor_noise,\n",
    "# SFO = SlidingFisherObservability(SEOM.O_df_sliding, time=SEOM.t_sim, lam=1e-6, R=0.1, #sensor_noise_dict=sensor_noise,\n",
    "                                 states=o_states, sensors=o_sensors, time_steps=o_time_steps, w=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bf67c35cfee44ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.702381Z",
     "start_time": "2024-12-17T10:35:25.688100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull out minimum error variance, 'time' column is the time vector shifted forward by w/2 and 'time_initial' is the original time\n",
    "EV_aligned = SFO.get_minimum_error_variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c35a1af82e1d008a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.718380Z",
     "start_time": "2024-12-17T10:35:25.703380Z"
    }
   },
   "outputs": [],
   "source": [
    "EV_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "184d5cc91eca4d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.920073Z",
     "start_time": "2024-12-17T10:35:25.719380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize observability matrix subset\n",
    "OI = ObservabilityMatrixImage(SFO.FO[0].O)\n",
    "OI.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24626b76820b9717",
   "metadata": {},
   "source": [
    "# Plot error variance as color on state time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "331553b8964df341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:25.935072Z",
     "start_time": "2024-12-17T10:35:25.921074Z"
    }
   },
   "outputs": [],
   "source": [
    "EV_no_nan = EV_aligned.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fc7f73e5912fcac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:27.264980Z",
     "start_time": "2024-12-17T10:35:25.936071Z"
    }
   },
   "outputs": [],
   "source": [
    "# states = list(SFO.FO[0].O.columns)\n",
    "states = [est_state_var for est_state_var in list(EV_no_nan.keys()) if est_state_var != 'time' and est_state_var != 'time_initial'] \n",
    "n_state = len(states)\n",
    "\n",
    "fig, ax = plt.subplots(n_state, 2, figsize=(6, n_state*2), dpi=150)\n",
    "ax = np.atleast_2d(ax)\n",
    "\n",
    "cmap = 'inferno_r'\n",
    "\n",
    "min_ev = np.min(EV_no_nan.iloc[:, 2:].values)\n",
    "max_ev = np.max(EV_no_nan.iloc[:, 2:].values)\n",
    "\n",
    "log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "cnorm = mpl.colors.LogNorm(10**log_tick_low, 10**log_tick_high)\n",
    "\n",
    "for n, state_name in enumerate(states):\n",
    "    # colorline(t_sim, x_sim[state_name], EV_no_nan[state_name].values, ax=ax[n, 0], cmap=cmap, norm=cnorm)\n",
    "    colorline(x_sim['x'], x_sim['y'], EV_no_nan[state_name].values, ax=ax[n, 0], cmap=cmap, norm=cnorm)\n",
    "    colorline(t_sim, EV_no_nan[state_name].values, EV_no_nan[state_name].values, ax=ax[n, 1], cmap=cmap, norm=cnorm)\n",
    "\n",
    "    # Colorbar\n",
    "    cax = ax[n, -1].inset_axes([1.03, 0.0, 0.04, 1.0])\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap), cax=cax,\n",
    "                        ticks=np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "    cbar.set_label('min. EV: ' + state_name, rotation=270, fontsize=7, labelpad=8)\n",
    "    cbar.ax.tick_params(labelsize=6)\n",
    "    \n",
    "    ax[n, 0].set_ylim(np.min(x_sim['y']) - 0.01, np.max(x_sim['y']) + 0.01)\n",
    "    ax[n, 0].set_xlim(np.min(x_sim['x']) - 0.01, np.max(x_sim['x']) + 0.01)\n",
    "    ax[n, 0].set_ylabel('y', fontsize=7)\n",
    "    ax[n, 0].set_xlabel('x', fontsize=7)\n",
    "    ax[n, 0].set_aspect(1.0)\n",
    "\n",
    "    ax[n, 1].set_ylim(10**log_tick_low, 10**log_tick_high)\n",
    "    ax[n, 1].set_yscale('log')\n",
    "    ax[n, 1].set_ylabel('min. EV: ' + state_name, fontsize=7)\n",
    "    ax[n, 1].set_yticks(np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.tick_params(axis='both', labelsize=6)\n",
    "    \n",
    "for a in ax[:, 1]:\n",
    "    a.set_xlabel('time (s)', fontsize=7)\n",
    "    a.set_xlim(-0.1, t_sim[-1] + 0.1)\n",
    "    \n",
    "# for a in ax[:, 1]:\n",
    "#     a.set_xlim(-0.1, t_sim[-1] + 0.1)\n",
    "\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.3, hspace=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8197e85",
   "metadata": {},
   "source": [
    "# Plot minEV hist by wind odor regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06092d71",
   "metadata": {},
   "source": [
    "## Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cec766e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on /src/JH_boilerplate/agent_evaluatiion/traj_analysis_preprocess.ipynb\n",
    "epoch_traj_df = epoch_traj_df.groupby(epoch_traj_df['ep_idx']).apply(log_analysis.calc_time_since_last_wind_change).reset_index(drop=True)\n",
    "wind_change_regime_threshold = 20\n",
    "import importlib\n",
    "importlib.reload(log_analysis)\n",
    "log_analysis.get_wind_change_regimes(epoch_traj_df, wind_change_frame_threshold=wind_change_regime_threshold, frame_rate=0.04, verbose=True)\n",
    "\n",
    "# based on /src/JH_boilerplate/figure_making/cosyne_abstract.ipynb\n",
    "def add_wind_odor_regime(traj_df_stacked):\n",
    "    traj_df_stacked['odor_wind_regime'] = 'NA'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='anemometric') & (traj_df_stacked['odor_01']==1)] = 'anemometric, on plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='anemometric') & (traj_df_stacked['odor_01']==0)] = 'anemometric, off plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='tracking') & (traj_df_stacked['odor_01']==1)] = 'tracking, on plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='tracking') & (traj_df_stacked['odor_01']==0)] = 'tracking, off plume'\n",
    "    \n",
    "add_wind_odor_regime(epoch_traj_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031cc677",
   "metadata": {},
   "source": [
    "# Plot 40 trials minEV hist by wind odor regimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f6567",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675fd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_pkls = ['/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_14421_37e2cd4be4c96943d0341849b40f81eb/noisy3x5b5_observability_test.pkl',\n",
    "            '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_17519_6aca800e09d4942c5d296ae7157fcf8b/noisy3x5b5_observability_test.pkl']\n",
    "eval_pkls = [obs_pkl.replace(\"_observability_test.pkl\", \".pkl\") for obs_pkl in obs_pkls]\n",
    "\n",
    "# load pkl file\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tamagotchi.eval.log_analysis as log_analysis\n",
    "\n",
    "with open(obs_pkls[0], 'rb') as f_handle:\n",
    "    observability_tupl = pickle.load(f_handle)\n",
    "    print(len(observability_tupl))\n",
    "with open(eval_pkls[0], 'rb') as f_handle:\n",
    "    # based on open_loop_perturbation.py\n",
    "    dataset = 'noisy3x5b5'\n",
    "    eval_folder = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_14421_37e2cd4be4c96943d0341849b40f81eb/'\n",
    "    # eval_folder = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_17519_6aca800e09d4942c5d296ae7157fcf8b/'\n",
    "    selected_df = log_analysis.get_selected_df(eval_folder, [dataset],\n",
    "                                            n_episodes_home=240,\n",
    "                                            n_episodes_other=240,  \n",
    "                                            balanced=False,\n",
    "                                            oob_only=False,\n",
    "                                            verbose=True)\n",
    "\n",
    "    traj_df_stacked, stacked_neural_activity = log_analysis.get_traj_and_activity_and_stack_them(selected_df, \n",
    "                                                                                                obtain_neural_activity = True, \n",
    "                                                                                                obtain_traj_df = True, \n",
    "                                                                                                get_traj_tmp = True,\n",
    "                                                                                                extended_metadata = True) # get_traj_tmp \n",
    "    print(traj_df_stacked.shape)\n",
    "    print(stacked_neural_activity.shape)\n",
    "# for item in observability_tupl:\n",
    "#     EV_no_nan, t_sim, x_sim, window_size, eps_idx = item\n",
    "    \n",
    "ls_EV_no_nan,ls_t_sim, ls_x_sim, ls_window_size, ls_eps_idx = zip(*observability_tupl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcae8b",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ef65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the trajectory data\n",
    "# select episodes that have observability matrices\n",
    "eps_at = [True if ep_i in ls_eps_idx else False for ep_i in traj_df_stacked['ep_idx'] ]\n",
    "subset_traj_df_stacked = traj_df_stacked[eps_at]\n",
    "subset_stacked_neural_activity = stacked_neural_activity[eps_at]\n",
    "\n",
    "\n",
    "# for every episode, drop the last row\n",
    "subset_traj_df_stacked.reset_index(drop=True, inplace=True)\n",
    "last_rows = subset_traj_df_stacked.groupby('ep_idx').tail(1).index\n",
    "print('dropping', len(last_rows), 'rows')\n",
    "# drop the last row of each episode\n",
    "filtered_df = subset_traj_df_stacked.drop(index=last_rows)\n",
    "filtered_neural_activity = np.delete(subset_stacked_neural_activity, last_rows, axis=0)\n",
    "\n",
    "# calculate time since last wind change and label wind regimes\n",
    "    # based on /src/JH_boilerplate/agent_evaluatiion/traj_analysis_preprocess.ipynb\n",
    "filtered_df = filtered_df.groupby('ep_idx').apply(log_analysis.calc_time_since_last_wind_change).reset_index(drop=True)\n",
    "wind_change_regime_threshold = 5\n",
    "log_analysis.get_wind_change_regimes(filtered_df, wind_change_frame_threshold=wind_change_regime_threshold, frame_rate=0.04, verbose=True)\n",
    "\n",
    "# based on /src/JH_boilerplate/figure_making/cosyne_abstract.ipynb\n",
    "def add_wind_odor_regime(traj_df_stacked):\n",
    "    traj_df_stacked['odor_wind_regime'] = 'NA'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='anemometric') & (traj_df_stacked['odor_01']==1)] = 'anemometric, on plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='anemometric') & (traj_df_stacked['odor_01']==0)] = 'anemometric, off plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='tracking') & (traj_df_stacked['odor_01']==1)] = 'tracking, on plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='tracking') & (traj_df_stacked['odor_01']==0)] = 'tracking, off plume'\n",
    "    \n",
    "add_wind_odor_regime(filtered_df)\n",
    "\n",
    "# create time column in filtered_df to match with EV_no_nan, starting from 0 to trial end \n",
    "filtered_df['time'] = filtered_df.groupby('ep_idx')['t_val'].transform(lambda x: x - x.iloc[0])\n",
    "filtered_df['time'] = filtered_df['time'].round(2)\n",
    "\n",
    "print(\"filtered_df shape\", filtered_df.shape)\n",
    "print(\"filtered_neural_activity shape\", filtered_neural_activity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95686629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the EV data \n",
    "# stack the EV data\n",
    "ls_EV_no_nan = [df.assign(ep_idx=ep_idx) for df, ep_idx in zip(ls_EV_no_nan, ls_eps_idx)]\n",
    "EV_no_nan = pd.concat(ls_EV_no_nan)\n",
    "print(EV_no_nan.shape)\n",
    "# Merge with filtered_dfa\n",
    "EV_no_nan['time'] = EV_no_nan['time'].round(2)\n",
    "EV_no_nan = EV_no_nan.merge(filtered_df[['odor_wind_regime', 'wind_regime', 'ep_idx', 'time', 'time_since_last_wind_change', 'odor_01']], on=['ep_idx', 'time'], how='inner')\n",
    "print(EV_no_nan.shape)\n",
    "# EV_no_nan.sort_values(by=['ep_idx', 'time'], inplace=True)\n",
    "# EV_no_nan.groupby('ep_idx')['time'].diff().value_counts() # checks out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43db352",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_change_regime_threshold = 5\n",
    "log_analysis.get_wind_change_regimes(EV_no_nan, wind_change_frame_threshold=wind_change_regime_threshold, frame_rate=0.04, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b701c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "selected_values = ['tracking', 'anemometric']\n",
    "filter_col = 'wind_regime'\n",
    "color_by = ['blue', 'red']\n",
    "\n",
    "for selected_val, color in zip(selected_values, color_by):\n",
    "    sub_df = EV_no_nan[EV_no_nan[filter_col]==selected_val]\n",
    "    print(sub_df['ep_idx'].nunique(), \"trials has\", selected_val, sub_df['ep_idx'].shape, \"plotted in color\", color)\n",
    "    plt.hist(np.log10(sub_df['zeta']),\n",
    "                # label='odor_wind_regime',\n",
    "                color=color,\n",
    "                alpha=0.5,\n",
    "                density=True,bins=12),   \n",
    "    # label plot to indicate the scale of x-axis\n",
    "    plt.xlabel('minimum estimation variance, log10')\n",
    "    plt.ylabel('density')\n",
    "    # remove the top and right spines, but keep the bottom and left, without using sns \n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    # legend \n",
    "    plt.legend(['> 0.2s after wind changed', '<= 0.2s after wind changed'], fontsize=10, loc='upper right')\n",
    "    # title\n",
    "    # plt.title('Wind observability')\n",
    "\n",
    "    plt.xlim(-2, 8)\n",
    "# plt.savefig('/src/JH_boilerplate/figure_making/cosyne_poster/noisy_14421_min_EV_w10_tracking_anemometric.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45831a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "selected_values = ['anemometric, off plume', 'anemometric, on plume']\n",
    "filter_col = 'odor_wind_regime'\n",
    "color_by = ['blue', 'red']\n",
    "\n",
    "for selected_val, color in zip(selected_values, color_by):\n",
    "    sub_df = EV_no_nan[EV_no_nan[filter_col]==selected_val]\n",
    "    print(sub_df['ep_idx'].nunique(), \"trials has\", selected_val, sub_df['ep_idx'].shape, \"plotted in color\", color)\n",
    "    plt.hist(np.log10(sub_df['zeta']),\n",
    "                # label='odor_wind_regime',\n",
    "                color=color,\n",
    "                alpha=0.5,\n",
    "                density=True,bins=12),   \n",
    "    # label plot to indicate the scale of x-axis\n",
    "    plt.xlabel('minimum estimation variance, log10')\n",
    "    plt.ylabel('density')\n",
    "    # remove the top and right spines, but keep the bottom and left, without using sns \n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    # legend \n",
    "    plt.legend(selected_values)\n",
    "\n",
    "    plt.xlim(-2, 8)\n",
    "plt.savefig('/src/JH_boilerplate/figure_making/cosyne_poster/noisy_14421_min_EV_w10_anemometric_on_off_plume.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd93f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "selected_values = ['tracking, off plume', 'tracking, on plume']\n",
    "filter_col = 'odor_wind_regime'\n",
    "color_by = ['blue', 'red']\n",
    "\n",
    "for selected_val, color in zip(selected_values, color_by):\n",
    "    print(EV_no_nan[filter_col].value_counts())\n",
    "    sub_df = EV_no_nan[EV_no_nan[filter_col]==selected_val]\n",
    "    print(sub_df['ep_idx'].nunique(), \"trials has\", selected_val, sub_df['ep_idx'].shape, \"plotted in color\", color)\n",
    "    plt.hist(np.log10(sub_df['zeta']),\n",
    "                # label='odor_wind_regime',\n",
    "                color=color,\n",
    "                alpha=0.5,\n",
    "                density=True,bins=12),   \n",
    "    # label plot to indicate the scale of x-axis\n",
    "    plt.xlabel('minimum estimation variance, log10')\n",
    "    plt.ylabel('density')\n",
    "    # remove the top and right spines, but keep the bottom and left, without using sns \n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    # legend \n",
    "    plt.legend(selected_values)\n",
    "\n",
    "    plt.xlim(-2, 8)\n",
    "plt.savefig('/src/JH_boilerplate/figure_making/cosyne_poster/noisy_14421_min_EV_w10_tracking_on_off_plume.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675879ed",
   "metadata": {},
   "source": [
    "# Colorize the neural trajectory based on the theoretical minimum error variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08be00e",
   "metadata": {},
   "source": [
    "## load data and preprocess - skip if done previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f214ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_pkls = ['/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_14421_37e2cd4be4c96943d0341849b40f81eb/noisy3x5b5_observability_test.pkl',\n",
    "            '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_17519_6aca800e09d4942c5d296ae7157fcf8b/noisy3x5b5_observability_test.pkl']\n",
    "eval_pkls = [obs_pkl.replace(\"_observability_test.pkl\", \".pkl\") for obs_pkl in obs_pkls]\n",
    "\n",
    "# load pkl file\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tamagotchi.eval.log_analysis as log_analysis\n",
    "\n",
    "with open(obs_pkls[0], 'rb') as f_handle:\n",
    "    observability_tupl = pickle.load(f_handle)\n",
    "    print(len(observability_tupl))\n",
    "with open(eval_pkls[0], 'rb') as f_handle:\n",
    "    # based on open_loop_perturbation.py\n",
    "    dataset = 'noisy3x5b5'\n",
    "    eval_folder = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_14421_37e2cd4be4c96943d0341849b40f81eb/'\n",
    "    # eval_folder = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_17519_6aca800e09d4942c5d296ae7157fcf8b/'\n",
    "    selected_df = log_analysis.get_selected_df(eval_folder, [dataset],\n",
    "                                            n_episodes_home=240,\n",
    "                                            n_episodes_other=240,  \n",
    "                                            balanced=False,\n",
    "                                            oob_only=False,\n",
    "                                            verbose=True)\n",
    "\n",
    "    traj_df_stacked, stacked_neural_activity = log_analysis.get_traj_and_activity_and_stack_them(selected_df, \n",
    "                                                                                                obtain_neural_activity = True, \n",
    "                                                                                                obtain_traj_df = True, \n",
    "                                                                                                get_traj_tmp = True,\n",
    "                                                                                                extended_metadata = True) # get_traj_tmp \n",
    "    print(traj_df_stacked.shape)\n",
    "    print(stacked_neural_activity.shape)\n",
    "# for item in observability_tupl:\n",
    "#     EV_no_nan, t_sim, x_sim, window_size, eps_idx = item\n",
    "    \n",
    "ls_EV_no_nan,ls_t_sim, ls_x_sim, ls_window_size, ls_eps_idx = zip(*observability_tupl)\n",
    "\n",
    "# Preprocess the trajectory data\n",
    "# select episodes that have observability matrices\n",
    "eps_at = [True if ep_i in ls_eps_idx else False for ep_i in traj_df_stacked['ep_idx'] ]\n",
    "subset_traj_df_stacked = traj_df_stacked[eps_at]\n",
    "subset_stacked_neural_activity = stacked_neural_activity[eps_at]\n",
    "\n",
    "# for every episode, drop the last row\n",
    "subset_traj_df_stacked.reset_index(drop=True, inplace=True)\n",
    "last_rows = subset_traj_df_stacked.groupby('ep_idx').tail(1).index\n",
    "print('dropping', len(last_rows), 'rows')\n",
    "# drop the last row of each episode\n",
    "filtered_df = subset_traj_df_stacked.drop(index=last_rows)\n",
    "filtered_neural_activity = np.delete(subset_stacked_neural_activity, last_rows, axis=0)\n",
    "\n",
    "# calculate time since last wind change and label wind regimes\n",
    "    # based on /src/JH_boilerplate/agent_evaluatiion/traj_analysis_preprocess.ipynb\n",
    "filtered_df = filtered_df.groupby('ep_idx').apply(log_analysis.calc_time_since_last_wind_change).reset_index(drop=True)\n",
    "wind_change_regime_threshold = 5\n",
    "log_analysis.get_wind_change_regimes(filtered_df, wind_change_frame_threshold=wind_change_regime_threshold, frame_rate=0.04, verbose=True)\n",
    "\n",
    "# based on /src/JH_boilerplate/figure_making/cosyne_abstract.ipynb\n",
    "def add_wind_odor_regime(traj_df_stacked):\n",
    "    traj_df_stacked['odor_wind_regime'] = 'NA'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='anemometric') & (traj_df_stacked['odor_01']==1)] = 'anemometric, on plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='anemometric') & (traj_df_stacked['odor_01']==0)] = 'anemometric, off plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='tracking') & (traj_df_stacked['odor_01']==1)] = 'tracking, on plume'\n",
    "    traj_df_stacked['odor_wind_regime'][(traj_df_stacked['wind_regime']=='tracking') & (traj_df_stacked['odor_01']==0)] = 'tracking, off plume'\n",
    "    \n",
    "add_wind_odor_regime(filtered_df)\n",
    "\n",
    "# create time column in filtered_df to match with EV_no_nan, starting from 0 to trial end \n",
    "filtered_df['time'] = filtered_df.groupby('ep_idx')['t_val'].transform(lambda x: x - x.iloc[0])\n",
    "filtered_df['time'] = filtered_df['time'].round(2)\n",
    "\n",
    "print(\"filtered_df shape\", filtered_df.shape)\n",
    "print(\"filtered_neural_activity shape\", filtered_neural_activity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bb7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the EV data \n",
    "# stack the EV data\n",
    "ls_EV_no_nan = [df.assign(ep_idx=ep_idx) for df, ep_idx in zip(ls_EV_no_nan, ls_eps_idx)]\n",
    "EV_no_nan = pd.concat(ls_EV_no_nan)\n",
    "print(EV_no_nan.shape)\n",
    "# Merge with filtered_dfa\n",
    "EV_no_nan['time'] = EV_no_nan['time'].round(2)\n",
    "EV_no_nan = EV_no_nan.merge(filtered_df[['odor_wind_regime', 'wind_regime', 'ep_idx', 'time', 'time_since_last_wind_change', 'odor_01']], on=['ep_idx', 'time'], how='inner')\n",
    "print(EV_no_nan.shape)\n",
    "# EV_no_nan.sort_values(by=['ep_idx', 'time'], inplace=True)\n",
    "# EV_no_nan.groupby('ep_idx')['time'].diff().value_counts() # checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c854976",
   "metadata": {},
   "source": [
    "## load plotting packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b2cb62a82362e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:35:27.280486Z",
     "start_time": "2024-12-17T10:35:27.264980Z"
    }
   },
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "import tamagotchi.config as config\n",
    "np.random.seed(config.seed_global)\n",
    "# Common\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "outcome_colormap = config.outcome_colormap\n",
    "regime_colormap = config.regime_colormap\n",
    "import os\n",
    "# Common\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "# print(plt.style.available)\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "dpi_save = 300\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# Interactive vs. CLI\n",
    "\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pca3d_figsize=(10,5)\n",
    "\n",
    "\n",
    "\n",
    "# https://seaborn.pydata.org/generated/seaborn.set_color_codes.html#seaborn.set_color_codes\n",
    "sns.color_palette()\n",
    "sns.set_color_codes(palette='deep')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df689a",
   "metadata": {},
   "source": [
    "## fit PCA based on selected trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a579448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition as skld\n",
    "n_comp = 15\n",
    "pca_common = skld.PCA(n_comp, whiten=False)\n",
    "pca_common.fit(filtered_neural_activity)\n",
    "\n",
    "# def plot_scree(pca_common):\n",
    "cum_evr=np.cumsum(pca_common.explained_variance_ratio_)\n",
    "n_comp=len(pca_common.explained_variance_ratio_)\n",
    "\n",
    "fig = plt.figure(figsize=(3.5,2.5))\n",
    "plt.plot(cum_evr)\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(n_comp, step=2, dtype=int))\n",
    "ax.set_xticklabels(np.arange(n_comp, step=2, dtype=int) + 1)\n",
    "ax.axhline(0.90, ls='--', c='grey', label='90% var. explained')\n",
    "plt.ylim(0.4, 1.05)\n",
    "\n",
    "pc_over = np.argwhere(list(cum_evr >= 0.9))[0]\n",
    "print(pc_over)\n",
    "ax.axvline(pc_over, ls=':', c='grey', label='$1^{st}$ PC ≥ 90% v.e.')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Principal Component (PC) Index\")\n",
    "plt.ylabel(\"Var. Explained [Fraction]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50cdf2",
   "metadata": {},
   "source": [
    "# neural traj with minEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5799f",
   "metadata": {},
   "source": [
    "## 3D image matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c6b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for creating a responsive plot \n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "print(\"EV_no_nan.shape\", EV_no_nan.shape)\n",
    "print(\"filtered_neural_activity.shape\", filtered_neural_activity.shape)\n",
    "\n",
    "min_ev = np.min(EV_no_nan['zeta'].values)\n",
    "max_ev = np.max(EV_no_nan['zeta'].values)\n",
    "log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "cnorm = mpl.colors.LogNorm(10**log_tick_low, 10**log_tick_high)\n",
    "cmap = 'inferno_r'\n",
    "fig = plt.figure(figsize=pca3d_figsize)\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "# ax = Axes3D(fig) # for 3D interactive plot\n",
    "for ep_idx, ep_EV in EV_no_nan.groupby('ep_idx'):\n",
    "    i = list(ep_EV.index)\n",
    "    ep_activity = filtered_neural_activity[i]\n",
    "    X_pca = pca_common.transform(ep_activity)\n",
    "    \n",
    "    # plot neural trajectory in 3D PCA space\n",
    "    ax.plot(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], linewidth=0.6, c='grey', alpha=1.0)\n",
    "\n",
    "    # color by minEV\n",
    "    c = ep_EV['zeta'].values\n",
    "    threshold = 10 # minEV threshold in radian \n",
    "    c_mapped = np.ma.masked_where(c > threshold, c)\n",
    "    sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], #s=10, \n",
    "                    c=c, \n",
    "                    alpha=0.85, norm=cnorm, cmap = 'inferno_r')\n",
    "    cax = ax.inset_axes([1.12, 0.0, 0.04, 1.0])\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap), cax=cax,\n",
    "                        ticks=np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "    cbar.set_label('min. EV: ' + 'zeta', rotation=270, fontsize=12, labelpad=12)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    ax.set_xlabel(f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})')\n",
    "    ax.set_ylabel(f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})')\n",
    "    ax.set_zlabel(f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})')\n",
    "\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e6511",
   "metadata": {},
   "source": [
    "## 3D interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20cb2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Determine color normalization range\n",
    "min_ev = np.min(EV_no_nan['zeta'].values)\n",
    "max_ev = np.max(EV_no_nan['zeta'].values)\n",
    "log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "\n",
    "threshold = 10  # MinEV threshold in radians\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Loop through episodes to add trajectories and scatter points\n",
    "for ep_idx, ep_EV in EV_no_nan.groupby('ep_idx'):\n",
    "    i = list(ep_EV.index)\n",
    "    ep_activity = filtered_neural_activity[i]\n",
    "    X_pca = pca_common.transform(ep_activity)\n",
    "\n",
    "    # Add trajectory (grey lines)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=X_pca[:, 0], \n",
    "        y=X_pca[:, 1], \n",
    "        z=X_pca[:, 2],\n",
    "        mode='lines',\n",
    "        line=dict(color='grey', width=1),\n",
    "        # name=f'Episode {ep_idx}'\n",
    "    ))\n",
    "\n",
    "    # Color by minEV\n",
    "    # c = ep_EV['zeta'].values\n",
    "    c_log = np.log10(ep_EV['zeta'].values)\n",
    "    # c_mapped = np.where(c > threshold, None, c)  # Mask values above threshold\n",
    "\n",
    "    # Add scatter points\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=X_pca[:, 0], \n",
    "        y=X_pca[:, 1], \n",
    "        z=X_pca[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=c_log,  # Color based on minEV\n",
    "            colorscale='Inferno_r',  # Inferno_r is the reverse of Inferno\n",
    "            cmin=log_tick_low,\n",
    "            cmax=log_tick_high,\n",
    "            colorbar=dict(\n",
    "                title=\"min. EV: zeta\",\n",
    "                tickvals=np.linspace(log_tick_low, log_tick_high, log_tick_high - log_tick_low + 1),\n",
    "                ticktext=[f\"{10**x:.2e}\" for x in np.linspace(log_tick_low, log_tick_high, log_tick_high - log_tick_low + 1)],\n",
    "                tickmode=\"array\"\n",
    "            ),\n",
    "            opacity=0.85\n",
    "        ),\n",
    "        # name=f'Episode {ep_idx} Points'\n",
    "    ))\n",
    "\n",
    "# Set axis labels\n",
    "fig.update_layout(\n",
    "    title=\"3D PCA Neural Trajectory\",\n",
    "    scene=dict(\n",
    "        xaxis_title=f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})',\n",
    "        yaxis_title=f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})',\n",
    "        zaxis_title=f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})',\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "\n",
    "# take out trace label\n",
    "fig.update_traces(showlegend=False)\n",
    "\n",
    "# Show interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472c77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save generated plotly figure as html\n",
    "fig.write_html(\"/src/JH_boilerplate/figure_making/cosyne_poster/noisy_14421_min_EV_w10_zeta.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264d207",
   "metadata": {},
   "source": [
    "## 3D interactive masked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define threshold for coloring\n",
    "threshold = 1  # Set your threshold here\n",
    "\n",
    "# Compute color normalization (log scale)\n",
    "min_ev = np.min(EV_no_nan['zeta'].values)\n",
    "max_ev = np.max(EV_no_nan['zeta'].values)\n",
    "log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "\n",
    "# Transform data into log scale for color normalization\n",
    "EV_no_nan['log_zeta'] = np.log10(EV_no_nan['zeta'])\n",
    "\n",
    "# Define the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate through episodes and add traces\n",
    "for ep_idx, ep_EV in EV_no_nan.groupby('ep_idx'):\n",
    "    i = list(ep_EV.index)\n",
    "    ep_activity = filtered_neural_activity[i]\n",
    "    X_pca = pca_common.transform(ep_activity)\n",
    "\n",
    "    # Create boolean masks per episode (Fixing the IndexError)\n",
    "    ep_below_threshold = ep_EV['zeta'] <= threshold\n",
    "    ep_above_threshold = ep_EV['zeta'] > threshold\n",
    "\n",
    "    # Plot neural trajectory as a grey line\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=X_pca[:, 0], y=X_pca[:, 1], z=X_pca[:, 2],\n",
    "        mode='lines',\n",
    "        line=dict(color='grey', width=1),\n",
    "        opacity=1.0,\n",
    "        # name=f'Episode {ep_idx} Trajectory'\n",
    "    ))\n",
    "\n",
    "    # Points below threshold (colored by colormap)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=X_pca[ep_below_threshold, 0], y=X_pca[ep_below_threshold, 1], z=X_pca[ep_below_threshold, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=ep_EV['log_zeta'][ep_below_threshold],  # Use log-transformed values\n",
    "            colorscale='inferno_r',\n",
    "            colorbar=dict(\n",
    "                title='min. EV (zeta)',\n",
    "                tickvals=np.linspace(log_tick_low, log_tick_high, log_tick_high - log_tick_low + 1),\n",
    "                ticktext=[f\"{10**x:.2e}\" for x in np.linspace(log_tick_low, log_tick_high, log_tick_high - log_tick_low + 1)],\n",
    "                len=0.75\n",
    "            ),\n",
    "            cmin=log_tick_low,\n",
    "            cmax=log_tick_high\n",
    "        ),\n",
    "        opacity=0.85,\n",
    "        # name=f'Episode {ep_idx} (Below Threshold)'\n",
    "    ))\n",
    "\n",
    "    # Points above threshold (colored black)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=X_pca[ep_above_threshold, 0], y=X_pca[ep_above_threshold, 1], z=X_pca[ep_above_threshold, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color='black'  # Set to black\n",
    "        ),\n",
    "        opacity=0.85,\n",
    "        # name=f'Episode {ep_idx} (Above Threshold)'\n",
    "    ))\n",
    "\n",
    "# Set axis labels\n",
    "fig.update_layout(\n",
    "    title=\"3D Neural Trajectories in PCA Space\",\n",
    "    scene=dict(\n",
    "        xaxis_title=f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})',\n",
    "        yaxis_title=f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})',\n",
    "        zaxis_title=f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    ")\n",
    "\n",
    "# take out trace label\n",
    "fig.update_traces(showlegend=False)\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29c410",
   "metadata": {},
   "source": [
    "## 3D gif over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68c5f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "importlib.reload(go)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Compute color normalization (log scale)\n",
    "min_ev = np.min(EV_no_nan['zeta'].values)\n",
    "max_ev = np.max(EV_no_nan['zeta'].values)\n",
    "log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "\n",
    "# Transform data into log scale for color normalization\n",
    "EV_no_nan['log_zeta'] = np.log10(EV_no_nan['zeta'])\n",
    "\n",
    "# Get unique time points\n",
    "timepoints = np.sort(EV_no_nan['time'].unique())\n",
    "\n",
    "# Initialize figure with the first frame's data\n",
    "first_time = timepoints[0]\n",
    "first_mask = EV_no_nan['time'] == first_time\n",
    "ep_EV_first = EV_no_nan[first_mask]\n",
    "\n",
    "# Get corresponding neural activity\n",
    "i_first = list(ep_EV_first.index)\n",
    "ep_activity_first = filtered_neural_activity[i_first]\n",
    "X_pca_first = pca_common.transform(ep_activity_first)\n",
    "\n",
    "# Create figure \n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=X_pca_first[:, 0],\n",
    "            y=X_pca_first[:, 1],\n",
    "            z=X_pca_first[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=4,\n",
    "                color=ep_EV_first['log_zeta'],  # Use log-transformed values\n",
    "                colorscale='inferno_r',\n",
    "                cmin=log_tick_low,\n",
    "                cmax=log_tick_high,\n",
    "                colorbar=dict(\n",
    "                    title='min. EV (zeta)',\n",
    "                    tickvals=np.linspace(log_tick_low, log_tick_high, log_tick_high - log_tick_low + 1),\n",
    "                    ticktext=[f\"{10**x:.2e}\" for x in np.linspace(log_tick_low, log_tick_high, log_tick_high - log_tick_low + 1)],\n",
    "                    len=0.75\n",
    "                )\n",
    "            ),\n",
    "            opacity=0.85\n",
    "        )\n",
    "    ],\n",
    "    layout=go.Layout(\n",
    "        title=\"3D Neural Trajectories Over Time\",\n",
    "        scene=dict(\n",
    "            xaxis_title=f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})',\n",
    "            yaxis_title=f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})',\n",
    "            zaxis_title=f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})',\n",
    "            aspectmode=\"cube\"  # Ensures proper 3D proportions\n",
    "        ),\n",
    "        updatemenus=[{\n",
    "            \"buttons\": [\n",
    "                {\n",
    "                    \"args\": [None, {\"frame\": {\"duration\": 200, \"redraw\": True}, \"fromcurrent\": True}],\n",
    "                    \"label\": \"Play\",\n",
    "                    \"method\": \"animate\"\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [[None], {\"frame\": {\"duration\": 0, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
    "                    \"label\": \"Pause\",\n",
    "                    \"method\": \"animate\"\n",
    "                }\n",
    "            ],\n",
    "            \"direction\": \"left\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 87},\n",
    "            \"showactive\": False,\n",
    "            \"type\": \"buttons\",\n",
    "            \"x\": 0.1,\n",
    "            \"xanchor\": \"right\",\n",
    "            \"y\": 0,\n",
    "            \"yanchor\": \"top\"\n",
    "        }]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    scene = dict(\n",
    "        xaxis = dict(nticks=4, range=[-3.8703774958848953, 4.689060643315315],),\n",
    "        yaxis = dict(nticks=4, range=[-3.799545295536518, 5.703847654163837],),\n",
    "        zaxis = dict(nticks=4, range=[-2.994434344271819, 4.160033928851286],),))\n",
    "\n",
    "\n",
    "# Create frames for animation\n",
    "frames = []\n",
    "for t in timepoints:\n",
    "    time_mask = EV_no_nan['time'] == t\n",
    "    ep_EV_t = EV_no_nan[time_mask]\n",
    "\n",
    "    # Get corresponding neural activity\n",
    "    i = list(ep_EV_t.index)\n",
    "    ep_activity_t = filtered_neural_activity[i]\n",
    "    X_pca_t = pca_common.transform(ep_activity_t)\n",
    "\n",
    "    # Append frame\n",
    "    frames.append(go.Frame(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=X_pca_t[:, 0],\n",
    "                y=X_pca_t[:, 1],\n",
    "                z=X_pca_t[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=4,\n",
    "                    color=ep_EV_t['log_zeta'],  # Use log-transformed values\n",
    "                    colorscale='inferno_r',\n",
    "                    cmin=log_tick_low,\n",
    "                    cmax=log_tick_high\n",
    "                ),\n",
    "                opacity=0.85\n",
    "            )\n",
    "        ],\n",
    "        name=str(t)\n",
    "    ))\n",
    "\n",
    "# Add frames to figure\n",
    "fig.frames = frames\n",
    "\n",
    "# Show interactive animation\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# is_recurrent = True\n",
    "# # logfiles = natsorted(glob.glob(model_dir + '*.pkl'))\n",
    "# # [ x.split('/')[-1] for x in logfiles ]\n",
    "# column_to_titlestring = {\n",
    "#     'odor_lastenc': 'Steps since last\\nplume encounter',\n",
    "#     'stray_distance': 'stray_distance', \n",
    "#     'odor_01': 'On/off plume',\n",
    "#     'odor_ma': 'Odor concentration MA [A.U.]',\n",
    "#     'odor_ewm': 'Odor concentration EWMA [A.U.]',\n",
    "#     'odor_enc': 'Odor encounters EWMA [A.U.]',\n",
    "#     'wind_theta_obs': 'Egocentric\\nwind angle [rad]',\n",
    "#     'agent_angle_ground': r'Head direction [rad]',\n",
    "#     'turn': 'Turn',\n",
    "#     'step': 'Step',\n",
    "#     'neural_velocity': r\"$\\Delta$h\",\n",
    "#     'ego_course_direction_theta': 'Course direction [rad]',\n",
    "#     'wind_angle_ground_theta': 'Wind direction [rad]',\n",
    "#     'zeta': 'Wind angle [rad]',\n",
    "# }\n",
    "\n",
    "# column_ticklabels = {\n",
    "#     'agent_angle_ground': [r'$-\\pi/2$', 0, r'$+\\pi/2$'],\n",
    "# }\n",
    "\n",
    "# column_ticks = {\n",
    "#     'agent_angle_ground': [0, 0.5, 1.0],\n",
    "# }\n",
    "\n",
    "\n",
    "# log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "# log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "# cnorm = mpl.colors.LogNorm(10**log_tick_low, 10**log_tick_high)\n",
    "\n",
    "# # for n, state_name in enumerate(states):\n",
    "# #     # colorline(t_sim, x_sim[state_name], EV_no_nan[state_name].values, ax=ax[n, 0], cmap=cmap, norm=cnorm)\n",
    "# #     colorline(x_sim['x'], x_sim['y'], EV_no_nan[state_name].values, ax=ax[n, 0], cmap=cmap, norm=cnorm)\n",
    "# #     colorline(t_sim, EV_no_nan[state_name].values, EV_no_nan[state_name].values, ax=ax[n, 1], cmap=cmap, norm=cnorm)\n",
    "\n",
    "# #     # Colorbar\n",
    "# #     cax = ax[n, -1].inset_axes([1.03, 0.0, 0.04, 1.0])\n",
    "# #     cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap), cax=cax,\n",
    "# #                         ticks=np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "# #     cbar.set_label('min. EV: ' + state_name, rotation=270, fontsize=7, labelpad=8)\n",
    "# #     cbar.ax.tick_params(labelsize=6)\n",
    "    \n",
    "    \n",
    "# # from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "# def plot_common_subspace_from_traj_neural_dfs(latent_activity_common_pca, EV_no_nan, colorby, save=True):\n",
    "#     fig = plt.figure(figsize=pca3d_figsize)\n",
    "#     ax = fig.add_subplot(projection='3d')\n",
    "#     colorby_prefix = None\n",
    "    \n",
    "#     X_pca = epoch_latent_activity_common_pca\n",
    "\n",
    "#     ax.plot(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], linewidth=0.6, c='grey', alpha=1.0)\n",
    "\n",
    "\n",
    "#     c = EV_no_nan['zeta'].values\n",
    "#     threshold = 10 # minEV threshold in radian \n",
    "#     c_mapped = np.ma.masked_where(c > threshold, c)\n",
    "#     sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], s=10, \n",
    "#                     c=c, \n",
    "#                     alpha=0.85, norm=cnorm, cmap = 'inferno_r')\n",
    "# #     cbar_ax = inset_axes(ax, \n",
    "# #                             width=\"30%\", \n",
    "# #                             height=\"3%\", \n",
    "# # #                              loc='upper right',\n",
    "# #                             bbox_to_anchor=(0.0, 0.45, 0.92, 0.4), # (x0, y0, width, height)\n",
    "# #                             bbox_transform=ax.transAxes,\n",
    "# #                         )\n",
    "#     # clb = plt.colorbar(sc, cbar_ax, orientation='horizontal') # ticks=[0., 1.]\n",
    "#     cax = ax.inset_axes([1.12, 0.0, 0.04, 1.0])\n",
    "#     cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap), cax=cax,\n",
    "#                         ticks=np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "#     cbar.set_label('min. EV: ' + state_name, rotation=270, fontsize=12, labelpad=12)\n",
    "#     cbar.ax.tick_params(labelsize=12)\n",
    "#     # move color bar to the right using inset_axes\n",
    "    \n",
    "    \n",
    "\n",
    "#     # https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n",
    "#     # divider = make_axes_locatable(ax)\n",
    "#     # cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "#     # plt.colorbar(sc, cax=cax)\n",
    "\n",
    "#     ax.set_xlabel(f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})')\n",
    "#     ax.set_ylabel(f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})')\n",
    "#     ax.set_zlabel(f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})')\n",
    "# #     plt.legend()\n",
    "#     plt.tight_layout()\n",
    "\n",
    "\n",
    "#     plt.show()\n",
    "#     if save:\n",
    "#         fname = f\"{outdir}/comsub_{colorby}_{model_seed}.png\"\n",
    "#         print(\"Saving:\", fname)\n",
    "#         fig.savefig(fname, dpi=dpi_save, bbox_inches='tight', transparent=False)\n",
    "\n",
    "#     # Just plot colorbar\n",
    "# #     if colorby not in ['outcome', 'regime']:\n",
    "# #         fig = plt.figure()\n",
    "# #         ax = plt.gca()\n",
    "# #         sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "# #                     s=10, c=c, cmap='copper', alpha=0.5, vmin=0)\n",
    "# #         plt.colorbar(sc, orientation='horizontal') # ticks=[0., 1.]\n",
    "\n",
    "# #         fname = f\"{outdir}/comsub_{colorby}_{model_seed}_colorbar.png\"\n",
    "# #         print(\"Saving:\", fname)\n",
    "# #         plt.savefig(fname, dpi=dpi_save, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# plot_common_subspace_from_traj_neural_dfs(epoch_latent_activity_common_pca,  EV_no_nan, 'zeta', save=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed5954",
   "metadata": {},
   "source": [
    "# deprecated one trial from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "671a2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "import tamagotchi.config as config\n",
    "np.random.seed(config.seed_global)\n",
    "# Common\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "outcome_colormap = config.outcome_colormap\n",
    "regime_colormap = config.regime_colormap\n",
    "import os\n",
    "# Common\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "# print(plt.style.available)\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "dpi_save = 300\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# Interactive vs. CLI\n",
    "\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pca3d_figsize=(10,5)\n",
    "\n",
    "\n",
    "\n",
    "# https://seaborn.pydata.org/generated/seaborn.set_color_codes.html#seaborn.set_color_codes\n",
    "sns.color_palette()\n",
    "sns.set_color_codes(palette='deep')\n",
    "\n",
    "import glob\n",
    "\n",
    "log_fname = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/eval/plume_14421_37e2cd4be4c96943d0341849b40f81eb/constantx5b5.pkl'\n",
    "\n",
    "seed='14421'\n",
    "model_fname = '/src/data/wind_sensing/apparent_wind_visual_feedback/sw_dist_logstep_wind_0.001_debug_yes_vec_norm_train_actor_std/weights/plume_14421_37e2cd4be4c96943d0341849b40f81eb.pt'\n",
    "# diffusionx = 0.5\n",
    "print(model_fname)\n",
    "# print(\"diffusionx ---->\", diffusionx)\n",
    "\n",
    "model_dir = model_fname.replace('.pt', '/')\n",
    "print(\"model_dir\", model_dir)\n",
    "\n",
    "eval_dir = model_dir.replace('weights', exp_folder)\n",
    "\n",
    "model_seed = model_dir.rstrip('/').split('/')[-1].split('_')[1]\n",
    "print(\"model_seed ---->\", model_seed)\n",
    "\n",
    "# outdir = f\"{model_dir}/report_common_subspace/\"\n",
    "# indir = f'{model_dir}/report_arch/' # to get best_window_lengths from report_correlations\n",
    "# os.makedirs(outdir, exist_ok=True)\n",
    "# print(f\"Outputing to {outdir}\")\n",
    "use_datasets = ['noisy3x5b5']\n",
    "# use_datasets = ['constantx5b5', 'switch45x5b5', 'noisy3x5b5']\n",
    "\n",
    "print(model_seed)\n",
    "selected_df = log_analysis.get_selected_df(eval_dir, \n",
    "                              use_datasets, \n",
    "                              n_episodes_home=240, \n",
    "                              n_episodes_other=240,\n",
    "                              min_ep_steps=0,\n",
    "                              balanced=False,\n",
    "                              oob_only=False,\n",
    "                              verbose =True) # get the pkl files \n",
    "print(selected_df.shape)\n",
    "\n",
    "select_at = [i for i, e_i in enumerate(selected_df['idx']) if e_i in EV_no_nan['ep_idx'].unique()]\n",
    "subset_df = selected_df.iloc[select_at]\n",
    "print(subset_df.shape)\n",
    "pca_common = log_analysis.get_pca_common(subset_df, \n",
    "                            n_comp=15, \n",
    "                            is_recurrent=is_recurrent)\n",
    "\n",
    "epoch_latent_activity_common_pca = pca_common.transform(epoch_latent_activity[:-1])\n",
    "\n",
    "is_recurrent = True\n",
    "# logfiles = natsorted(glob.glob(model_dir + '*.pkl'))\n",
    "# [ x.split('/')[-1] for x in logfiles ]\n",
    "column_to_titlestring = {\n",
    "    'odor_lastenc': 'Steps since last\\nplume encounter',\n",
    "    'stray_distance': 'stray_distance', \n",
    "    'odor_01': 'On/off plume',\n",
    "    'odor_ma': 'Odor concentration MA [A.U.]',\n",
    "    'odor_ewm': 'Odor concentration EWMA [A.U.]',\n",
    "    'odor_enc': 'Odor encounters EWMA [A.U.]',\n",
    "    'wind_theta_obs': 'Egocentric\\nwind angle [rad]',\n",
    "    'agent_angle_ground': r'Head direction [rad]',\n",
    "    'turn': 'Turn',\n",
    "    'step': 'Step',\n",
    "    'neural_velocity': r\"$\\Delta$h\",\n",
    "    'ego_course_direction_theta': 'Course direction [rad]',\n",
    "    'wind_angle_ground_theta': 'Wind direction [rad]',\n",
    "    'zeta': 'Wind angle [rad]',\n",
    "}\n",
    "\n",
    "column_ticklabels = {\n",
    "    'agent_angle_ground': [r'$-\\pi/2$', 0, r'$+\\pi/2$'],\n",
    "}\n",
    "\n",
    "column_ticks = {\n",
    "    'agent_angle_ground': [0, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "log_tick_high = int(np.ceil(np.log10(max_ev)))\n",
    "log_tick_low = int(np.floor(np.log10(min_ev)))\n",
    "cnorm = mpl.colors.LogNorm(10**log_tick_low, 10**log_tick_high)\n",
    "\n",
    "# for n, state_name in enumerate(states):\n",
    "#     # colorline(t_sim, x_sim[state_name], EV_no_nan[state_name].values, ax=ax[n, 0], cmap=cmap, norm=cnorm)\n",
    "#     colorline(x_sim['x'], x_sim['y'], EV_no_nan[state_name].values, ax=ax[n, 0], cmap=cmap, norm=cnorm)\n",
    "#     colorline(t_sim, EV_no_nan[state_name].values, EV_no_nan[state_name].values, ax=ax[n, 1], cmap=cmap, norm=cnorm)\n",
    "\n",
    "#     # Colorbar\n",
    "#     cax = ax[n, -1].inset_axes([1.03, 0.0, 0.04, 1.0])\n",
    "#     cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap), cax=cax,\n",
    "#                         ticks=np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "#     cbar.set_label('min. EV: ' + state_name, rotation=270, fontsize=7, labelpad=8)\n",
    "#     cbar.ax.tick_params(labelsize=6)\n",
    "    \n",
    "    \n",
    "# from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "def plot_common_subspace_from_traj_neural_dfs(epoch_latent_activity_common_pca, EV_no_nan, colorby, save=True):\n",
    "    fig = plt.figure(figsize=pca3d_figsize)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    colorby_prefix = None\n",
    "    \n",
    "    X_pca = epoch_latent_activity_common_pca\n",
    "\n",
    "    ax.plot(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], linewidth=0.6, c='grey', alpha=1.0)\n",
    "\n",
    "\n",
    "    c = EV_no_nan['zeta'].values\n",
    "    threshold = 10 # minEV threshold in radian \n",
    "    c_mapped = np.ma.masked_where(c > threshold, c)\n",
    "    sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], s=10, \n",
    "                    c=c, \n",
    "                    alpha=0.85, norm=cnorm, cmap = 'inferno_r')\n",
    "#     cbar_ax = inset_axes(ax, \n",
    "#                             width=\"30%\", \n",
    "#                             height=\"3%\", \n",
    "# #                              loc='upper right',\n",
    "#                             bbox_to_anchor=(0.0, 0.45, 0.92, 0.4), # (x0, y0, width, height)\n",
    "#                             bbox_transform=ax.transAxes,\n",
    "#                         )\n",
    "    # clb = plt.colorbar(sc, cbar_ax, orientation='horizontal') # ticks=[0., 1.]\n",
    "    cax = ax.inset_axes([1.12, 0.0, 0.04, 1.0])\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap), cax=cax,\n",
    "                        ticks=np.logspace(log_tick_low, log_tick_high, log_tick_high-log_tick_low + 1))\n",
    "    cbar.set_label('min. EV: ' + state_name, rotation=270, fontsize=12, labelpad=12)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    # move color bar to the right using inset_axes\n",
    "    \n",
    "    \n",
    "\n",
    "    # https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n",
    "    # divider = make_axes_locatable(ax)\n",
    "    # cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    # plt.colorbar(sc, cax=cax)\n",
    "\n",
    "    ax.set_xlabel(f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})')\n",
    "    ax.set_ylabel(f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})')\n",
    "    ax.set_zlabel(f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})')\n",
    "#     plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fname = f\"{outdir}/comsub_{colorby}_{model_seed}.png\"\n",
    "        print(\"Saving:\", fname)\n",
    "        fig.savefig(fname, dpi=dpi_save, bbox_inches='tight', transparent=False)\n",
    "\n",
    "    # Just plot colorbar\n",
    "#     if colorby not in ['outcome', 'regime']:\n",
    "#         fig = plt.figure()\n",
    "#         ax = plt.gca()\n",
    "#         sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "#                     s=10, c=c, cmap='copper', alpha=0.5, vmin=0)\n",
    "#         plt.colorbar(sc, orientation='horizontal') # ticks=[0., 1.]\n",
    "\n",
    "#         fname = f\"{outdir}/comsub_{colorby}_{model_seed}_colorbar.png\"\n",
    "#         print(\"Saving:\", fname)\n",
    "#         plt.savefig(fname, dpi=dpi_save, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "plot_common_subspace_from_traj_neural_dfs(epoch_latent_activity_common_pca,  EV_no_nan, 'zeta', save=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a73ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5e8f0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot neural-trajectories on common subspace\n",
    "# %matplotlib notebook \n",
    "# importlib.reload(log_analysis)\n",
    "\n",
    "# %config InlineBackend.figure_format = 'retina' # For manuscript\n",
    "# mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "import tamagotchi.eval.agent_analysis as agent_analysis\n",
    "import pandas as pd\n",
    "importlib.reload(agent_analysis)\n",
    "importlib.reload(log_analysis)\n",
    "importlib.reload(config)\n",
    "\n",
    "\n",
    "column_to_titlestring = {\n",
    "    'odor_lastenc': 'Steps since last\\nplume encounter',\n",
    "    'stray_distance': 'stray_distance', \n",
    "    'odor_01': 'On/off plume',\n",
    "    'odor_ma': 'Odor concentration MA [A.U.]',\n",
    "    'odor_ewm': 'Odor concentration EWMA [A.U.]',\n",
    "    'odor_enc': 'Odor encounters EWMA [A.U.]',\n",
    "    'wind_theta_obs': 'Egocentric\\nwind angle [rad]',\n",
    "    'agent_angle_ground': r'Head direction [rad]',\n",
    "    'turn': 'Turn',\n",
    "    'step': 'Step',\n",
    "    'neural_velocity': r\"$\\Delta$h\",\n",
    "    'ego_course_direction_theta': 'Course direction [rad]',\n",
    "    'wind_angle_ground_theta': 'Wind direction [rad]',\n",
    "}\n",
    "\n",
    "column_ticklabels = {\n",
    "    'agent_angle_ground': [r'$-\\pi/2$', 0, r'$+\\pi/2$'],\n",
    "}\n",
    "\n",
    "column_ticks = {\n",
    "    'agent_angle_ground': [0, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def plot_common_subspace_all(selected_df, colorby, save=True):\n",
    "    fig = plt.figure(figsize=pca3d_figsize)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "    colorby_prefix = None\n",
    "    # if '_best' in colorby:\n",
    "    #     colorby_prefix = colorby.replace('_best', '')\n",
    "    #     window_length = best_window_lengths[colorby_prefix]\n",
    "    #     colorby = f\"{colorby_prefix}_{window_length}\"\n",
    "    #     print(\"best\", colorby, colorby_prefix)\n",
    "\n",
    "#     plot_df = selected_df.groupby(['dataset', 'outcome']).head(5)\n",
    "    plot_df = selected_df.groupby(['dataset', 'outcome']).tail(20)\n",
    "    # plot_df = selected_df.groupby(['dataset', 'outcome']).sample(5, replace=True)\n",
    "\n",
    "    colorbar_is_plotted = False\n",
    "    for idx, row in plot_df.iterrows():\n",
    "        outcome = row['outcome']\n",
    "        ep_activity = log_analysis.get_activity(row['log'], is_recurrent, do_plot=False)\n",
    "#         ep_activity =  pd.DataFrame(ep_activity).diff().fillna(0).to_numpy() # if colorby == 'neural_velocity' else ep_activity\n",
    "\n",
    "        traj_df = log_analysis.get_traj_df_tmp(row['log'], \n",
    "                   extended_metadata=True, \n",
    "                   squash_action=True, \n",
    "                   n_history=100,\n",
    "                   seed=model_seed)\n",
    "\n",
    "        X_pca = pca_common.transform(ep_activity)\n",
    "#         X_pca = pd.DataFrame(X_pca).diff().to_numpy()\n",
    "\n",
    "        ax.plot(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], linewidth=0.6, c='grey', alpha=1.0)\n",
    "\n",
    "        if colorby == 'outcome':\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], s=10, \n",
    "                            c=outcome_colormap[outcome], label='outcome')\n",
    "            continue\n",
    "        elif colorby == 'regime':    \n",
    "            regime_colors = [ regime_colormap[x] for x in traj_df['regime'] ]\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], s=10, \n",
    "                            c=regime_colors, \n",
    "#                             edgecolors=None,\n",
    "                            alpha=0.85)\n",
    "            continue\n",
    "        elif colorby in ['wind_theta_obs', 'agent_angle_ground', 'ego_course_direction_theta']:  \n",
    "            # Cyclic colormap: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "            # Seaborn: https://stackoverflow.com/questions/23712207/cyclic-colormap-without-visual-distortions-for-use-in-phase-angle-plots\n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='twilight', alpha=0.5, vmin=0, vmax=1)\n",
    "            continue\n",
    "        elif 'odor_lastenc' in colorby:    \n",
    "            vmax = 35 # fixed for odor_lastenc\n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0, vmax=vmax)\n",
    "            continue\n",
    "        elif 'odor_ma_' in colorby:    \n",
    "            vmax = None\n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0, vmax=vmax)\n",
    "            continue\n",
    "        elif 'odor' in colorby:    \n",
    "            vmax = 1.0\n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0, vmax=vmax)\n",
    "            continue\n",
    "        elif colorby == 'stray_distance':    \n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0, vmax=2)\n",
    "            continue\n",
    "        elif colorby in ['step', 'turn']:    \n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0, vmax=1)\n",
    "            continue        \n",
    "        elif colorby in ['step_dt1', 'turn_dt1']:    \n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=c.min(), vmax=c.max())\n",
    "            continue        \n",
    "        elif colorby == 'neural_velocity':    \n",
    "            c = pd.DataFrame(ep_activity).diff().fillna(0).apply(np.linalg.norm, axis=1)\n",
    "#             c /= pd.DataFrame(ep_activity).apply(np.linalg.norm, axis=1)\n",
    "#             c = np.log(1+c)\n",
    "#             c = np.clip(0, 1.5, c)\n",
    "            # print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0)\n",
    "            continue\n",
    "        else:    \n",
    "            c = traj_df[colorby]\n",
    "            print(colorby, c.min(), c.max())\n",
    "            sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                            s=10, c=c, cmap='copper', alpha=0.5, vmin=0)\n",
    "\n",
    "#     if not batchmode:\n",
    "#         plt.title(f\"{colorby} [{model_seed}]]\")\n",
    "\n",
    "    # https://stackoverflow.com/questions/18211967/position-colorbar-inside-figure\n",
    "    if colorby not in ['outcome', 'regime']:\n",
    "#         plt.colorbar(sc)\n",
    "        cbar_ax = inset_axes(ax, \n",
    "                             width=\"30%\", \n",
    "                             height=\"3%\", \n",
    "#                              loc='upper right',\n",
    "                             bbox_to_anchor=(0.0, 0.45, 0.92, 0.4), # (x0, y0, width, height)\n",
    "                             bbox_transform=ax.transAxes,\n",
    "                            )\n",
    "        clb = plt.colorbar(sc, cbar_ax, orientation='horizontal') # ticks=[0., 1.]\n",
    "#         cbar_ax.set_title(colorby)\n",
    "        if colorby in column_to_titlestring.keys():\n",
    "            cbar_ax.set_title(column_to_titlestring[colorby])\n",
    "        if colorby in column_ticklabels.keys():\n",
    "            clb.set_ticks(column_ticks[colorby])\n",
    "            clb.set_ticklabels(column_ticklabels[colorby])\n",
    "\n",
    "        print(\"Here1\")\n",
    "        if colorby_prefix in column_to_titlestring.keys():\n",
    "            print(\"Here2\")\n",
    "            cbar_ax.set_title(column_to_titlestring[colorby_prefix])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n",
    "    # divider = make_axes_locatable(ax)\n",
    "    # cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    # plt.colorbar(sc, cax=cax)\n",
    "\n",
    "    ax.set_xlabel(f'PC1 (VarExp: {pca_common.explained_variance_ratio_[0]:0.2f})')\n",
    "    ax.set_ylabel(f'PC2 (VarExp: {pca_common.explained_variance_ratio_[1]:0.2f})')\n",
    "    ax.set_zlabel(f'PC3 (VarExp: {pca_common.explained_variance_ratio_[2]:0.2f})')\n",
    "#     plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if colorby == 'regime':    \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        patch1 = mpatches.Patch(color=regime_colormap['TRACK'], label='Track')   \n",
    "        patch2 = mpatches.Patch(color=regime_colormap['RECOVER'], label='Recover')   \n",
    "        patch3 = mpatches.Patch(color=regime_colormap['SEARCH'], label='Lost')   \n",
    "        handles.extend([patch1, patch2, patch3])\n",
    "        plt.legend(handles=handles, loc='upper right', bbox_to_anchor=(0.95, 0.9))\n",
    "\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fname = f\"{outdir}/comsub_{colorby}_{model_seed}.png\"\n",
    "        print(\"Saving:\", fname)\n",
    "        fig.savefig(fname, dpi=dpi_save, bbox_inches='tight', transparent=False)\n",
    "\n",
    "    # Just plot colorbar\n",
    "#     if colorby not in ['outcome', 'regime']:\n",
    "#         fig = plt.figure()\n",
    "#         ax = plt.gca()\n",
    "#         sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], \n",
    "#                     s=10, c=c, cmap='copper', alpha=0.5, vmin=0)\n",
    "#         plt.colorbar(sc, orientation='horizontal') # ticks=[0., 1.]\n",
    "\n",
    "#         fname = f\"{outdir}/comsub_{colorby}_{model_seed}_colorbar.png\"\n",
    "#         print(\"Saving:\", fname)\n",
    "#         plt.savefig(fname, dpi=dpi_save, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "colorbys = [\n",
    "        # 'outcome', \n",
    "        # 'regime', \n",
    "    #    'odor_lastenc',\n",
    "    #    'stray_distance', \n",
    "    #    'odor_01', \n",
    "    #    'odor_ma_best',\n",
    "    #    'odor_ewm_best',\n",
    "    #    'odor_enc_best',\n",
    "#            'odor_ma_8',\n",
    "        # 'wind_theta_obs',\n",
    "    #    'agent_angle_ground',\n",
    "       'turn',\n",
    "    #    'turn_dt1',\n",
    "    #    'step',\n",
    "    #    'step_dt1',\n",
    "    #    'neural_velocity'\n",
    "    ]\n",
    "for colorby in colorbys:\n",
    "    plot_common_subspace_all(selected_df[selected_df['outcome'] == 'HOME'], colorby, save=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
